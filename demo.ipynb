{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5FsBCMwQ2qq"
      },
      "source": [
        "### Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2ks-sH2FQWoK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98f1b960-b4fe-4999-aebd-94ed4aefe075"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/replication-of-generating-reviews-discovering-sentiment/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pi26aKwEVrId",
        "outputId": "204c98ba-f604-4db6-9fb1-8313b37f4312"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/replication-of-generating-reviews-discovering-sentiment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mrGJFzL7pdg",
        "outputId": "10b588f3-ca35-4d0d-84e8-802ddf8f73aa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data  demo.ipynb  encoder.py  LICENSE  model  __pycache__  README.md  sst_binary_demo.py  utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Install and Import Dependencies"
      ],
      "metadata": {
        "id": "kF0NSW_nqo7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import html\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_curve, roc_auc_score, f1_score\n",
        "from encoder import Model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZNoLOR0quMM",
        "outputId": "8a966cea-5a7b-406a-e6b1-cf2af3cfacec"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/compat/v2_compat.py:108: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Demo The TextVectorization Model"
      ],
      "metadata": {
        "id": "ckh4sjm4nOqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model()\n",
        "text = [\"I couldn't figure out\"]\n",
        "text_features = model.transform(text)\n",
        "print(text_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEM6V-mlnrmh",
        "outputId": "b7d1282b-e987-4ac0-999e-f64b1ce14015"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1260: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "dim is deprecated, use axis instead\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.189 seconds to transform 1 examples\n",
            "[[-0.12958631 -0.7414906   0.06320142 ...  0.12817442  0.07800508\n",
            "   0.14032528]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_features.shape)"
      ],
      "metadata": {
        "id": "s-yfJ-jyoWMg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d80f5d0-21ac-42af-9275-1d4a1f699d64"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 4096)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(text_features))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrJIviIDw_bY",
        "outputId": "3d37b0a0-e14a-4bca-c8b6-006bf345132e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Define Function"
      ],
      "metadata": {
        "id": "lONM7UxNoXEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_sst(path):\n",
        "    data = pd.read_csv(path)\n",
        "    X = data['sentence'].values.tolist()\n",
        "    Y = data['label'].values\n",
        "    return X, Y\n",
        "\n",
        "def sst_binary(data_dir='data/',train_dir=\"train_binary_sent.csv\", val_dir=\"dev_binary_sent.csv\", test_dir=\"test_binary_sent.csv\"):\n",
        "    \"\"\"\n",
        "    Most standard models make use of a preprocessed/tokenized/lowercased version\n",
        "    of Stanford Sentiment Treebank. Our model extracts features from a version\n",
        "    of the dataset using the raw text instead which we've included in the data\n",
        "    folder.\n",
        "    \"\"\"\n",
        "    trX, trY = load_sst(os.path.join(data_dir, train_dir))\n",
        "    vaX, vaY = load_sst(os.path.join(data_dir, val_dir))\n",
        "    teX, teY = load_sst(os.path.join(data_dir, test_dir))\n",
        "    return trX, vaX, teX, trY, vaY, teY\n",
        "\n",
        "def preprocess(text, front_pad='\\n ', end_pad=' '):\n",
        "    text = html.unescape(text)\n",
        "    text = text.replace('\\n', ' ').strip()\n",
        "    text = front_pad+text+end_pad\n",
        "    text = text.encode()\n",
        "    return text\n",
        "\n",
        "def train_with_reg_cv(trX, trY, vaX, vaY, teX=None, teY=None, penalty='l1',C=2**np.arange(-8, 1).astype(np.float64), seed=42):\n",
        "    scores = []\n",
        "    for i, c in enumerate(C):\n",
        "        model = LogisticRegression(C=c, penalty=penalty, random_state=seed+i, solver='liblinear')\n",
        "        model.fit(trX, trY)\n",
        "        score = model.score(vaX, vaY)\n",
        "        scores.append(score)\n",
        "    c = C[np.argmax(scores)]\n",
        "    model = LogisticRegression(C=c, penalty=penalty, random_state=seed+len(C), solver='liblinear')\n",
        "    model.fit(trX, trY)\n",
        "    nnotzero = np.sum(model.coef_ != 0)\n",
        "    if teX is not None and teY is not None:\n",
        "        score = model.score(teX, teY)*100.\n",
        "    else:\n",
        "        score = model.score(vaX, vaY)*100.\n",
        "    return score, c, nnotzero, model"
      ],
      "metadata": {
        "id": "5cFOsCl2sk2_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Load the data\n",
        "\n",
        "Let's take a moment to understand the format of the data. Each example is a sentence representing the movie review and a corresponding label. The sentence is not preprocessed in any way. The label is an integer value of either 0 or 1, where 0 is a negative review, and 1 is a positive review."
      ],
      "metadata": {
        "id": "H6C6syVTvCPH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SST"
      ],
      "metadata": {
        "id": "3nuxtzu25QIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SST_train_dir = 'SST/SST_train.csv'\n",
        "SST_val_dir = 'SST/SST_val.csv'\n",
        "SST_test_dir = 'SST/SST_test.csv'\n",
        "SST_trX, SST_vaX, SST_teX, SST_trY, SST_vaY, SST_teY = sst_binary('data/',SST_train_dir, SST_val_dir, SST_test_dir)"
      ],
      "metadata": {
        "id": "k2sGDMnlvO0P"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the length of train , test dataset\n",
        "print(\"Training entries: {}, test entries: {}\".format(len(SST_trX), len(SST_teX)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzzGMI0EvGr0",
        "outputId": "c4fe2287-0519-4612-c889-09def69bd0bd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training entries: 6920, test entries: 1821\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's print first 10 examples."
      ],
      "metadata": {
        "id": "-qkjQU6YvV3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SST_trX[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KwHHAqEvWB9",
        "outputId": "5776df60-5508-4517-cbcd-ef4fe910b30a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A stirring, funny and finally transporting re-imagining of Beauty and the Beast and 1930s horror films',\n",
              " 'Apparently reassembled from the cutting-room floor of any given daytime soap.',\n",
              " \"They presume their audience won't sit still for a sociology lesson, however entertainingly presented, so they trot out the conventional science-fiction elements of bug-eyed monsters and futuristic women in skimpy clothes.\",\n",
              " 'This is a visually stunning rumination on love, memory, history and the war between art and commerce.',\n",
              " \"Jonathan Parker's Bartleby should have been the be-all-end-all of the modern-office anomie films.\",\n",
              " 'Campanella gets the tone just right -- funny in the middle of sad in the middle of hopeful.',\n",
              " 'A fan film that for the uninitiated plays better on video with the sound turned down.',\n",
              " 'Béart and Berling are both superb, while Huppert ... is magnificent.',\n",
              " 'A little less extreme than in the past, with longer exposition sequences between them, and with fewer gags to break the tedium.',\n",
              " 'The film is strictly routine.']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's also print the first 10 labels."
      ],
      "metadata": {
        "id": "nBBDnYyQwM4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SST_trY[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAAXo3JfwM_L",
        "outputId": "d0085aa4-27b7-4509-f636-56ee0ca6c3bc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 1, 1, 1, 0, 1, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Amazon"
      ],
      "metadata": {
        "id": "fI9VoF60F0n1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Amazon_train_dir = 'Amazon/amazon_train.csv'\n",
        "Amazon_val_dir = 'Amazon/amazon_val.csv'\n",
        "Amazon_test_dir = 'Amazon/amazon_test.csv'\n",
        "Amazon_trX, Amazon_vaX, Amazon_teX, Amazon_trY, Amazon_vaY, Amazon_teY = sst_binary('data/',Amazon_train_dir, Amazon_val_dir, Amazon_test_dir)"
      ],
      "metadata": {
        "id": "IH2m0yb0F0n2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the length of train , test dataset\n",
        "print(\"Training entries: {}, test entries: {}\".format(len(Amazon_trX), len(Amazon_teX)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a00d84d-25b4-4550-cfbf-7f0efe670aba",
        "id": "lI5F-k4tF0n3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training entries: 24238, test entries: 6926\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's print first 5 examples."
      ],
      "metadata": {
        "id": "fOg8I0HeF0n4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Amazon_trX[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6febeebf-a27d-4517-ea71-238845249a9b",
        "id": "D6P8TswnF0n4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Purchased this as an upgrade to the first generation Kindle Paperwhite. The backlight is greatly improved, the display is of a higher quality, the words are clearer and the internal process is a lot quicker  opening books and page flipping is noticeably speedier.The one thing that does annoy me about the 3rd generation Paperwhite is the way it's manufactured  when you hold it at a certain angle and you look at the bottom of the screen, you can see a small section of the display covered in the e-ink used to render the words and images on the rest of the screen. At first I thought this was a manufacturing defect, so I took it back to Best Buy and exchanged it for the same model, only to find that the second model had the same issue, except more-visible.This appears to have something to do with the way the display is placed behind the bezel during the manufacturing process. When the Paperwhite first came out, it was the crown jewel of Amazon's e-reader line, and Amazon was careful to precision-craft the devices. Now, that honor falls to the more-expensive Voyage, with the Paperwhite becoming the flagship, but still cheaper, option in the Kindle lineup, meaning the manufacturing quality of the Paperwhite is likely a bit reduced compared to that of the Voyage.This won't be a huge annoyance for some people. It is for me. And it's seriously made me consider whether it's worth contacting Amazon over.For everyone else, though, this is a great e-reader and well worth the money. If you're looking for an e-reader, this is the one to buy.\",\n",
              " 'Bought this for my wife and she loves it definitely worth it',\n",
              " 'Bought this Kindle for our grandchild and he loves it.For anyone who just loves to read this size and weight is perfect!!!!',\n",
              " 'So fun and useful. We play with it and rely several task with it.',\n",
              " 'Great for streaming, TV shows! Highly recommend this product!']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's also print the first 5 labels."
      ],
      "metadata": {
        "id": "pjCnkCyAF0n4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Amazon_trY[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36eb6cd1-da98-43d8-af12-83b4136134da",
        "id": "FJ6KwUKVF0n4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Yelp"
      ],
      "metadata": {
        "id": "KFbhx7nmJFJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Yelp data\n",
        "Yelp_train_dir = 'Yelp/yelp_train.csv'\n",
        "Yelp_val_dir = 'Yelp/yelp_val.csv'\n",
        "Yelp_test_dir = 'Yelp/yelp_test.csv'\n",
        "Yelp_trX, Yelp_vaX, Yelp_teX, Yelp_trY, Yelp_vaY, Yelp_teY = sst_binary('data/',Yelp_train_dir, Yelp_val_dir, Yelp_test_dir)"
      ],
      "metadata": {
        "id": "DjgeWmsqJFJW"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the length of train , test dataset\n",
        "print(\"Training entries: {}, test entries: {}\".format(len(Yelp_trX), len(Yelp_teX)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d15d8e99-8859-4084-8e6e-64cab8ca5426",
        "id": "hCLXvR95JFJX"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training entries: 416000, test entries: 40000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's print first 5 examples."
      ],
      "metadata": {
        "id": "CIYsSzOqJFJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Yelp_teX[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3c0ee48-1c78-4c68-eda4-797fc7cc8a17",
        "id": "JtG6optbJFJY"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I got \\'new\\' tires from them and within two weeks got a flat. I took my car to a local mechanic to see if i could get the hole patched, but they said the reason I had a flat was because the previous patch had blown - WAIT, WHAT? I just got the tire and never needed to have it patched? This was supposed to be a new tire. \\\\nI took the tire over to Flynn\\'s and they told me that someone punctured my tire, then tried to patch it. So there are resentful tire slashers? I find that very unlikely. After arguing with the guy and telling him that his logic was far fetched he said he\\'d give me a new tire \\\\\"this time\\\\\". \\\\nI will never go back to Flynn\\'s b/c of the way this guy treated me and the simple fact that they gave me a used tire!',\n",
              " \"Don't waste your time.  We had two different people come to our house to give us estimates for a deck (one of them the OWNER).  Both times, we never heard from them.  Not a call, not the estimate, nothing.\",\n",
              " 'All I can say is the worst! We were the only 2 people in the place for lunch, the place was freezing and loaded with kids toys! 2 bicycles, a scooter, and an electronic keyboard graced the dining room. A fish tank with filthy, slimy fingerprints smeared all over it is there for your enjoyment.\\\\n\\\\nOur food came... no water to drink, no tea, medium temperature food. Of course its cold, just like the room, I never took my jacket off! The plates are too small, you food spills over onto some semi-clean tables as you sit in your completely worn out booth seat. The fried noodles were out of a box and nasty, the shrimp was mushy, the fried rice was bright yellow.\\\\n\\\\nWe asked for water, they brought us 1 in a SOLO cup for 2 people. I asked for hot tea, they said 10 minutes. What Chinese restaurant does not have hot tea available upon request?\\\\n\\\\nOver all.... my first and last visit to this place. The only good point was that it was cheap, and deservingly so.',\n",
              " \"I have been to this restaurant twice and was disappointed both times. I won't go back. The first time we were there almost 3 hours. It took forever to order and then forever for our food to come and the place was empty. When I complained the manager was very rude and tried to blame us for taking to long to order. It made no sense, how could we order when the waitress wasn't coming to the table? After arguing with me he ended up taking $6 off of our $200+ bill. Ridiculous. If it were up to me I would have never returned. Unfortunately my family decided to go here again tonight. Again it took a long time to get our food. My food was cold and bland, my kids food was cold. My husbands salmon was burnt to a crisp and my sister in law took one bite of her trout and refused to eat any more because she claims it was so disgusting. The wedding soup and bread were good, but that's it! My drink sat empty throughout my meal and never got refilled even when I asked. Bad food, slow service and rude managers. I'll pass on this place if my family decides to go again. Not worth it at all with all the other good Italian options around.\",\n",
              " \"Food was NOT GOOD at all! My husband & I ate here a couple weeks ago for the first time. I ordered a salad & basil pesto cream pasta & my husband ordered the spinach & feta pasta. The salad was just a huge plate of spring mix (nothing else in it) with WAY to much vinegar dressing. My lettuce was drowning in the vinegar. My pesto pasta had no flavor (did not taste like a cream sauce to me) & the pesto was so runny/watery & way too much sauce not enough noodles. My husband's pasta had even less flavor than mine. We ate about a quarter of the food & couldn't even finish it. We took it home & it was so bad I didn't even eat my leftovers. And I hate wasting food!! Plus the prices are expensive for the amount of food you get & of course the poor quality. Don't waste your time eating here. There are much better Italian restaurants in Pittsburgh.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's also print the first 5 labels."
      ],
      "metadata": {
        "id": "L19FKMxmJFJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Yelp_teY[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8cf9904-90b5-481b-e88b-52866eafa389",
        "id": "t4Rs3W3xJFJY"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Defining and Fitting the Classifiers"
      ],
      "metadata": {
        "id": "MUm2U4dcJFJY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We reproduce the original code with a Logistic Regression on top of the text vectorizer model to classify the sentiment"
      ],
      "metadata": {
        "id": "L5xgMn_8Mngm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SST"
      ],
      "metadata": {
        "id": "KA-lxaTuG9dx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SST_trXt = model.transform(SST_trX)\n",
        "SST_vaXt = model.transform(SST_vaX)\n",
        "SST_teXt = model.transform(SST_teX)\n",
        "\n",
        "# Build models with L1 and L2 regularization\n",
        "SST_full_rep_acc_l1, SST_c_l1, SST_nnotzero_l1, SST_model_l1 = train_with_reg_cv(SST_trXt, SST_trY, SST_vaXt, SST_vaY, SST_teXt, SST_teY, penalty='l1')\n",
        "SST_full_rep_acc_l2, SST_c_l2, SST_nnotzero_l2, SST_model_l2 = train_with_reg_cv(SST_trXt, SST_trY, SST_vaXt, SST_vaY, SST_teXt, SST_teY, penalty='l2')\n",
        "\n",
        "print('L1 Regularization Results:')\n",
        "print('%05.2f test accuracy' % SST_full_rep_acc_l1)\n",
        "print('%05.2f regularization coef' % SST_c_l1)\n",
        "print('%05d features used' % SST_nnotzero_l1)\n",
        "\n",
        "print('L2 Regularization Results:')\n",
        "print('%05.2f test accuracy' % SST_full_rep_acc_l2)\n",
        "print('%05.2f regularization coef' % SST_c_l2)\n",
        "print('%05d features used' % SST_nnotzero_l2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwQA_2Wftv7L",
        "outputId": "eb956682-8c16-4513-da18-82c4891ef94c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44.894 seconds to transform 6920 examples\n",
            "6.189 seconds to transform 872 examples\n",
            "12.520 seconds to transform 1821 examples\n",
            "L1 Regularization Results:\n",
            "91.76 test accuracy\n",
            "00.25 regularization coef\n",
            "00141 features used\n",
            "L2 Regularization Results:\n",
            "91.76 test accuracy\n",
            "00.03 regularization coef\n",
            "04096 features used\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Amazon"
      ],
      "metadata": {
        "id": "wKMYSA_YHML6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Amazon_trXt = model.transform(Amazon_trX)\n",
        "Amazon_vaXt = model.transform(Amazon_vaX)\n",
        "Amazon_teXt = model.transform(Amazon_teX)\n",
        "# classification\n",
        "# Build models with L1 and L2 regularization\n",
        "Amazon_full_rep_acc_l1, Amazon_c_l1, Amazon_nnotzero_l1, Amazon_model_l1 = train_with_reg_cv(Amazon_trXt, Amazon_trY, Amazon_vaXt, Amazon_vaY, Amazon_teXt, Amazon_teY, penalty='l1')\n",
        "Amazon_full_rep_acc_l2, Amazon_c_l2, Amazon_nnotzero_l2, Amazon_model_l2 = train_with_reg_cv(Amazon_trXt, Amazon_trY, Amazon_vaXt, Amazon_vaY, Amazon_teXt, Amazon_teY, penalty='l2')\n",
        "\n",
        "print('L1 Regularization Results:')\n",
        "print('%05.2f test accuracy' % Amazon_full_rep_acc_l1)\n",
        "print('%05.2f regularization coef' % Amazon_c_l1)\n",
        "print('%05d features used' % Amazon_nnotzero_l1)\n",
        "\n",
        "print('L2 Regularization Results:')\n",
        "print('%05.2f test accuracy' % Amazon_full_rep_acc_l2)\n",
        "print('%05.2f regularization coef' % Amazon_c_l2)\n",
        "print('%05d features used' % Amazon_nnotzero_l2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "479cd227-6b06-4a44-a430-6ba797296b73",
        "id": "bvRpcEobHML7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "245.507 seconds to transform 24238 examples\n",
            "33.270 seconds to transform 3462 examples\n",
            "71.659 seconds to transform 6926 examples\n",
            "L1 Regularization Results:\n",
            "95.24 test accuracy\n",
            "00.12 regularization coef\n",
            "00171 features used\n",
            "L2 Regularization Results:\n",
            "95.05 test accuracy\n",
            "00.03 regularization coef\n",
            "04096 features used\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Yelp"
      ],
      "metadata": {
        "id": "W8M2ivLxMPJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Yelp_trXt = model.transform(Yelp_trX)\n",
        "Yelp_vaXt = model.transform(Yelp_vaX)\n",
        "Yelp_teXt = model.transform(Yelp_teX)\n",
        "# Build models with L1 and L2 regularization\n",
        "Yelp_full_rep_acc_l1, Yelp_c_l1, Yelp_nnotzero_l1, Yelp_model_l1 = train_with_reg_cv(Yelp_trXt, Yelp_trY, Yelp_vaXt, Yelp_vaY, Yelp_teXt, Yelp_teY, penalty='l1')\n",
        "Yelp_full_rep_acc_l2, Yelp_c_l2, Yelp_nnotzero_l2, Yelp_model_l2 = train_with_reg_cv(Yelp_trXt, Yelp_trY, Yelp_vaXt, Yelp_vaY, Yelp_teXt, Yelp_teY, penalty='l2')\n",
        "\n",
        "print('L1 Regularization Results:')\n",
        "print('%05.2f test accuracy' % Yelp_full_rep_acc_l1)\n",
        "print('%05.2f regularization coef' % Yelp_c_l1)\n",
        "print('%05d features used' % Yelp_nnotzero_l1)\n",
        "\n",
        "print('L2 Regularization Results:')\n",
        "print('%05.2f test accuracy' % Yelp_full_rep_acc_l2)\n",
        "print('%05.2f regularization coef' % Yelp_c_l2)\n",
        "print('%05d features used' % Yelp_nnotzero_l2)"
      ],
      "metadata": {
        "id": "4kT78vDLMPJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Evaluation"
      ],
      "metadata": {
        "id": "TB4af7ETKGBB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Distribution of Results"
      ],
      "metadata": {
        "id": "4Kh9MdWZOm-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a single figure with subplots\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# Plot the histograms for SST_sentiment_unit\n",
        "SST_sentiment_unit = SST_trXt[:, 2000]\n",
        "axes[0].hist(SST_sentiment_unit[SST_trY == 0], bins=25, alpha=0.5, label='neg')\n",
        "axes[0].hist(SST_sentiment_unit[SST_trY == 1], bins=25, alpha=0.5, label='pos')\n",
        "axes[0].set_title('SST Sentiment Unit')\n",
        "axes[0].legend()\n",
        "\n",
        "# Plot the histograms for Amazon_sentiment_unit\n",
        "Amazon_sentiment_unit = Amazon_trXt[:, 2000]\n",
        "axes[1].hist(Amazon_sentiment_unit[Amazon_trY == 0], bins=25, alpha=0.5, label='neg')\n",
        "axes[1].hist(Amazon_sentiment_unit[Amazon_trY == 1], bins=25, alpha=0.5, label='pos')\n",
        "axes[1].set_title('Amazon Sentiment Unit')\n",
        "axes[1].legend()\n",
        "\n",
        "# Plot the histograms for Yelp_sentiment_unit\n",
        "Yelp_sentiment_unit = Yelp_trXt[:, 2000]\n",
        "axes[2].hist(Yelp_sentiment_unit[Yelp_trY == 0], bins=25, alpha=0.5, label='neg')\n",
        "axes[2].hist(Yelp_sentiment_unit[Yelp_trY == 1], bins=25, alpha=0.5, label='pos')\n",
        "axes[2].set_title('Yelp Sentiment Unit')\n",
        "axes[2].legend()\n",
        "\n",
        "# Adjust layout for better spacing\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the combined plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EbIcgbVnHML8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accuracy and F1 score"
      ],
      "metadata": {
        "id": "fdr3bfPgNzBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy and F1 score for SST dataset\n",
        "SST_accuracy = accuracy_score(SST_teY, SST_model_l1.predict(SST_teXt))\n",
        "SST_f1 = f1_score(SST_teY, SST_model_l1.predict(SST_teXt))\n",
        "\n",
        "# Calculate accuracy and F1 score for Amazon dataset\n",
        "Amazon_accuracy = accuracy_score(Amazon_teY, Amazon_model_l1.predict(Amazon_teXt))\n",
        "Amazon_f1 = f1_score(Amazon_teY, Amazon_model_l1.predict(Amazon_teXt))\n",
        "\n",
        "# Calculate accuracy and F1 score for Yelp dataset\n",
        "Yelp_accuracy = accuracy_score(Yelp_teY, Yelp_model_l1.predict(Yelp_teXt))\n",
        "Yelp_f1 = f1_score(Yelp_teY, Yelp_model_l1.predict(Yelp_teXt))\n",
        "\n",
        "# Print accuracy and F1 score for all datasets\n",
        "print(f'''Accuracy: SST data - {round(SST_accuracy*100, 2)}%\n",
        "F1 Score: SST data - {round(SST_f1*100, 2)}%\n",
        "Accuracy: Amazon data - {round(Amazon_accuracy*100, 2)}%\n",
        "F1 Score: Amazon data - {round(Amazon_f1*100, 2)}%\n",
        "Accuracy: Yelp data - {round(Yelp_accuracy*100, 2)}%\n",
        "F1 Score: Yelp data - {round(Yelp_f1*100, 2)}%''')"
      ],
      "metadata": {
        "id": "kRpXC5eCQWGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classification matrix"
      ],
      "metadata": {
        "id": "mxHol7jsOI7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate and print classification report for SST dataset\n",
        "SST_report = classification_report(SST_teY, SST_model_l1.predict(SST_teXt))\n",
        "print(\"Classification Report - SST data:\")\n",
        "print(SST_report)\n",
        "\n",
        "# Calculate and print classification report for Amazon dataset\n",
        "Amazon_report = classification_report(Amazon_teY, Amazon_model_l1.predict(Amazon_teXt))\n",
        "print(\"Classification Report - Amazon data:\")\n",
        "print(Amazon_report)\n",
        "\n",
        "# Calculate and print classification report for Yelp dataset\n",
        "Yelp_report = classification_report(Yelp_teY, Yelp_model_l1.predict(Yelp_teXt))\n",
        "print(\"Classification Report - Yelp data:\")\n",
        "print(Yelp_report)"
      ],
      "metadata": {
        "id": "YjtiJBBHRf8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ROC curve"
      ],
      "metadata": {
        "id": "Y19-a2skOXbZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate and plot ROC curve for SST dataset\n",
        "SST_fpr, SST_tpr, _ = roc_curve(SST_teY, SST_model_l1.predict_proba(SST_teXt)[:, 1])\n",
        "SST_auc = auc(SST_fpr, SST_tpr)\n",
        "\n",
        "# Calculate and plot ROC curve for Amazon dataset\n",
        "Amazon_fpr, Amazon_tpr, _ = roc_curve(Amazon_teY, Amazon_model_l1.predict_proba(Amazon_teXt)[:, 1])\n",
        "Amazon_auc = auc(Amazon_fpr, Amazon_tpr)\n",
        "\n",
        "# Calculate and plot ROC curve for Yelp dataset\n",
        "Yelp_fpr, Yelp_tpr, _ = roc_curve(Yelp_teY, Yelp_model_l1.predict_proba(Yelp_teXt)[:, 1])\n",
        "Yelp_auc = auc(Yelp_fpr, Yelp_tpr)\n",
        "\n",
        "# Create subplots\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# Plot ROC curve for SST dataset\n",
        "axes[0].plot(SST_fpr, SST_tpr, color='darkorange', lw=2, label='SST ROC curve (area = {:.2f})'.format(SST_auc))\n",
        "axes[0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "axes[0].set_xlim([0.0, 1.0])\n",
        "axes[0].set_ylim([0.0, 1.05])\n",
        "axes[0].set_xlabel('False Positive Rate')\n",
        "axes[0].set_ylabel('True Positive Rate')\n",
        "axes[0].set_title('SST ROC Curve')\n",
        "axes[0].legend(loc=\"lower right\")\n",
        "\n",
        "# Plot ROC curve for Amazon dataset\n",
        "axes[1].plot(Amazon_fpr, Amazon_tpr, color='blue', lw=2, label='Amazon ROC curve (area = {:.2f})'.format(Amazon_auc))\n",
        "axes[1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "axes[1].set_xlim([0.0, 1.0])\n",
        "axes[1].set_ylim([0.0, 1.05])\n",
        "axes[1].set_xlabel('False Positive Rate')\n",
        "axes[1].set_ylabel('True Positive Rate')\n",
        "axes[1].set_title('Amazon ROC Curve')\n",
        "axes[1].legend(loc=\"lower right\")\n",
        "\n",
        "# Plot ROC curve for Yelp dataset\n",
        "axes[2].plot(Yelp_fpr, Yelp_tpr, color='green', lw=2, label='Yelp ROC curve (area = {:.2f})'.format(Yelp_auc))\n",
        "axes[2].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "axes[2].set_xlim([0.0, 1.0])\n",
        "axes[2].set_ylim([0.0, 1.05])\n",
        "axes[2].set_xlabel('False Positive Rate')\n",
        "axes[2].set_ylabel('True Positive Rate')\n",
        "axes[2].set_title('Yelp ROC Curve')\n",
        "axes[2].legend(loc=\"lower right\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sACBGZQQuwn1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}